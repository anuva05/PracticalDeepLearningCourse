{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Lesson7-RNN_numbers.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuva05/PracticalDeepLearningCourse/blob/master/Lesson7_RNN_numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpmsV2jDxtO7",
        "colab_type": "text"
      },
      "source": [
        "# Human numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tcnm8DWxtO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps30WQ9LxtPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJwtBw43yaNG",
        "colab_type": "text"
      },
      "source": [
        "Toy dataset that contains numbers written in English, numbers are in ascending order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWwcpDLfxtPH",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muGmlyF_xtPJ",
        "colab_type": "code",
        "outputId": "ec71422a-1cd0-4674-da01-1fbd3306242c",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "path.ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/home/ubuntu/.fastai/data/human_numbers/train.txt'),\n",
              " PosixPath('/home/ubuntu/.fastai/data/human_numbers/valid.txt')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1nV5B7ZxtPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh1-KVKPxtPQ",
        "colab_type": "code",
        "outputId": "2d34a2f5-7ad7-4256-aa61-df0162e6eaaf",
        "colab": {}
      },
      "source": [
        "train_txt = readnums('train.txt'); train_txt[0][:80]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO2k1ZMJxtPU",
        "colab_type": "code",
        "outputId": "8a412e19-bfca-4652-be5a-b65cc187040d",
        "colab": {}
      },
      "source": [
        "valid_txt = readnums('valid.txt'); valid_txt[0][-80:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' nine thousand nine hundred ninety eight, nine thousand nine hundred ninety nine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_Pi3_NxtPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training and validation sets\n",
        "train = TextList(train_txt, path=path)\n",
        "valid = TextList(valid_txt, path=path)\n",
        "\n",
        "#create databunch\n",
        "src = ItemLists(path=path, train=train, valid=valid).label_for_lm()\n",
        "data = src.databunch(bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAnlhfHlxtPe",
        "colab_type": "code",
        "outputId": "95f11430-dee0-4c56-f780-18947aad14ce",
        "colab": {}
      },
      "source": [
        "train[0].text[:80]\n",
        "#xx in fast.ai is special token. 'bos' is start of document."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos one , two , three , four , five , six , seven , eight , nine , ten , eleve'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyluMJqxtPh",
        "colab_type": "code",
        "outputId": "45fa049e-3059-41b2-81d9-22f910c40ef0",
        "colab": {}
      },
      "source": [
        "#number of tokens in validation set\n",
        "len(data.valid_ds[0][0].data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnEe-NWyxtPl",
        "colab_type": "code",
        "outputId": "f73837d0-6439-43c2-e31e-6e7f1633028d",
        "colab": {}
      },
      "source": [
        "#BPTT =Backprop thru time = sequence length\n",
        "# Divide document into 64 pieces\n",
        "# 64 equally sized pieces of document - and in each piece, look at a list of 70 words to look at at one time\n",
        "data.bptt, len(data.valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t5EKkaLxtPq",
        "colab_type": "code",
        "outputId": "b6ba5c34-c84b-442f-e096-fab90266787a",
        "colab": {}
      },
      "source": [
        "13017/70/bs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.905580357142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dQxieNwxtPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it = iter(data.valid_dl)\n",
        "x1,y1 = next(it)\n",
        "x2,y2 = next(it)\n",
        "x3,y3 = next(it)\n",
        "it.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfNq2JaextPz",
        "colab_type": "code",
        "outputId": "f54be818-f911-4a50-cf9f-7349ff0ce29f",
        "colab": {}
      },
      "source": [
        "x1.numel()+x2.numel()+x3.numel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SUI1wNextP2",
        "colab_type": "code",
        "outputId": "305cc494-55db-4df7-9b6a-b4140ef6f85e",
        "colab": {}
      },
      "source": [
        "x1.shape,y1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 70]), torch.Size([64, 70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90lzTHAxtP4",
        "colab_type": "code",
        "outputId": "8b7bb406-9e7d-42d5-ea8c-9c9235813c76",
        "colab": {}
      },
      "source": [
        "x2.shape,y2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 70]), torch.Size([64, 70]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXhXO-A9xtP7",
        "colab_type": "code",
        "outputId": "863e540c-6bd3-4e0a-a8b0-f41715defb14",
        "colab": {}
      },
      "source": [
        "x1[:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  8, 10, 11, 12, 10,  9,  8,  9, 13, 18, 24, 18, 14, 15, 10, 18,  8,\n",
              "         9,  8, 18, 24, 18, 10, 18, 10,  9,  8, 18, 19, 10, 25, 19, 22, 19, 19,\n",
              "        23, 19, 10, 13, 10, 10,  8, 13,  8, 19,  9, 19, 34, 16, 10,  9,  8, 16,\n",
              "         8, 19,  9, 19, 10, 19, 10, 19, 19, 19], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC8yZ-PFxtP-",
        "colab_type": "code",
        "outputId": "fd852119-df8f-4146-8a45-47766cdffa6f",
        "colab": {}
      },
      "source": [
        "y1[:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 18, 26,  9,  8, 11, 31, 18, 25,  9, 10, 14, 10,  9,  8, 14, 10, 18,\n",
              "        25, 18, 10, 17, 10, 17,  8, 17, 20, 18,  9,  9, 19,  8, 10, 15, 10, 10,\n",
              "        12, 10, 12,  8, 12, 13, 19,  9, 19, 10, 23, 10,  8,  8, 15, 16, 19,  9,\n",
              "        19, 10, 23, 10, 18,  8, 18, 10, 10,  9], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rYS4Z3uxtQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grab the vocab\n",
        "v = data.valid_ds.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n64fuMSAxtQE",
        "colab_type": "code",
        "outputId": "3ad0985f-11b0-4223-fab8-3bb0c9a1446c",
        "colab": {}
      },
      "source": [
        "#If we want to see what the original text was, use textify()\n",
        "v.textify(x1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlyMVq_bxtQH",
        "colab_type": "code",
        "outputId": "00280c6d-5d4b-4e97-ceb7-c573ceb955bd",
        "colab": {}
      },
      "source": [
        "v.textify(y1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phs2LZBMxtQL",
        "colab_type": "code",
        "outputId": "356d7c45-5fc0-445d-a463-3e5717126d86",
        "colab": {}
      },
      "source": [
        "v.textify(x2[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thousand eighteen , eight thousand nineteen , eight thousand twenty , eight thousand twenty one , eight thousand twenty two , eight thousand twenty three , eight thousand twenty four , eight thousand twenty five , eight thousand twenty six , eight thousand twenty seven , eight thousand twenty eight , eight thousand twenty nine , eight thousand thirty , eight thousand thirty one , eight thousand thirty two ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozWwJ62xxtQN",
        "colab_type": "code",
        "outputId": "26d61e53-b2af-44df-d86c-151f0969621d",
        "colab": {}
      },
      "source": [
        "v.textify(x3[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eight thousand thirty three , eight thousand thirty four , eight thousand thirty five , eight thousand thirty six , eight thousand thirty seven , eight thousand thirty eight , eight thousand thirty nine , eight thousand forty , eight thousand forty one , eight thousand forty two , eight thousand forty three , eight thousand forty four , eight thousand forty five , eight thousand forty six , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-2GtG29xtQQ",
        "colab_type": "code",
        "outputId": "9d2dedcf-4702-4ba8-b480-700ff7fc84ca",
        "colab": {}
      },
      "source": [
        "#Batch #2\n",
        "v.textify(x1[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "', eight thousand forty six , eight thousand forty seven , eight thousand forty eight , eight thousand forty nine , eight thousand fifty , eight thousand fifty one , eight thousand fifty two , eight thousand fifty three , eight thousand fifty four , eight thousand fifty five , eight thousand fifty six , eight thousand fifty seven , eight thousand fifty eight , eight thousand fifty nine ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtdE9CsyxtQS",
        "colab_type": "code",
        "outputId": "052879d1-0725-4341-e604-d142a2054a0a",
        "colab": {}
      },
      "source": [
        "v.textify(x2[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eight thousand sixty , eight thousand sixty one , eight thousand sixty two , eight thousand sixty three , eight thousand sixty four , eight thousand sixty five , eight thousand sixty six , eight thousand sixty seven , eight thousand sixty eight , eight thousand sixty nine , eight thousand seventy , eight thousand seventy one , eight thousand seventy two , eight thousand seventy three , eight thousand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MwiKcWwxtQW",
        "colab_type": "code",
        "outputId": "16407d77-c98f-475c-ae56-881f6e0021b9",
        "colab": {}
      },
      "source": [
        "v.textify(x3[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'seventy four , eight thousand seventy five , eight thousand seventy six , eight thousand seventy seven , eight thousand seventy eight , eight thousand seventy nine , eight thousand eighty , eight thousand eighty one , eight thousand eighty two , eight thousand eighty three , eight thousand eighty four , eight thousand eighty five , eight thousand eighty six , eight thousand eighty seven , eight thousand eighty'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXnIpMAhxtQa",
        "colab_type": "code",
        "outputId": "d8a93f1e-bcf5-4856-acea-2102f06c236d",
        "colab": {}
      },
      "source": [
        "v.textify(x3[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ninety , nine thousand nine hundred ninety one , nine thousand nine hundred ninety two , nine thousand nine hundred ninety three , nine thousand nine hundred ninety four , nine thousand nine hundred ninety five , nine thousand nine hundred ninety six , nine thousand nine hundred ninety seven , nine thousand nine hundred ninety eight , nine thousand nine hundred ninety nine xxbos eight thousand one , eight'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb5zVvfsxtQc",
        "colab_type": "code",
        "outputId": "9d63d168-d2c3-474b-cdf6-25e17252d3e2",
        "colab": {}
      },
      "source": [
        "data.show_batch(ds_type=DatasetType.Valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>  <col width='5%'>  <col width='95%'>  <tr>\n",
              "    <th>idx</th>\n",
              "    <th>text</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>0</th>\n",
              "    <th>thousand forty seven , eight thousand forty eight , eight thousand forty nine , eight thousand fifty , eight thousand fifty one , eight thousand fifty two , eight thousand fifty three , eight thousand fifty four , eight thousand fifty five , eight thousand fifty six , eight thousand fifty seven , eight thousand fifty eight , eight thousand fifty nine , eight thousand sixty , eight thousand sixty</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>eight , eight thousand eighty nine , eight thousand ninety , eight thousand ninety one , eight thousand ninety two , eight thousand ninety three , eight thousand ninety four , eight thousand ninety five , eight thousand ninety six , eight thousand ninety seven , eight thousand ninety eight , eight thousand ninety nine , eight thousand one hundred , eight thousand one hundred one , eight thousand one</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>thousand one hundred twenty four , eight thousand one hundred twenty five , eight thousand one hundred twenty six , eight thousand one hundred twenty seven , eight thousand one hundred twenty eight , eight thousand one hundred twenty nine , eight thousand one hundred thirty , eight thousand one hundred thirty one , eight thousand one hundred thirty two , eight thousand one hundred thirty three , eight thousand</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>three , eight thousand one hundred fifty four , eight thousand one hundred fifty five , eight thousand one hundred fifty six , eight thousand one hundred fifty seven , eight thousand one hundred fifty eight , eight thousand one hundred fifty nine , eight thousand one hundred sixty , eight thousand one hundred sixty one , eight thousand one hundred sixty two , eight thousand one hundred sixty three</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>thousand one hundred eighty three , eight thousand one hundred eighty four , eight thousand one hundred eighty five , eight thousand one hundred eighty six , eight thousand one hundred eighty seven , eight thousand one hundred eighty eight , eight thousand one hundred eighty nine , eight thousand one hundred ninety , eight thousand one hundred ninety one , eight thousand one hundred ninety two , eight thousand</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CECZd3p8xtQf",
        "colab_type": "text"
      },
      "source": [
        "## Single fully connected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVe4ssJ_xtQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = src.databunch(bs=bs, bptt=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Iq_NWkxtQh",
        "colab_type": "code",
        "outputId": "e8cd4df8-cbfd-4c21-e258-ad1c503b0287",
        "colab": {}
      },
      "source": [
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3]), torch.Size([64, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggu6c0eOxtQk",
        "colab_type": "code",
        "outputId": "8f7767b4-f1cd-484d-fb40-68e9693dd897",
        "colab": {}
      },
      "source": [
        "nv = len(v.itos); nv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atxrVrFZxtQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8039th6xtQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss4(input,target): return F.cross_entropy(input, target[:,-1])\n",
        "def acc4 (input,target): return accuracy(input, target[:,-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Z6pOnJxtQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Simple model \n",
        "class Model0(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = self.bn(F.relu(self.h_h(self.i_h(x[:,0]))))\n",
        "        if x.shape[1]>1:\n",
        "            h = h + self.i_h(x[:,1])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        if x.shape[1]>2:\n",
        "            h = h + self.i_h(x[:,2])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKZBhosSxtQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model0(), loss_func=loss4, metrics=acc4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZGMDUQLxtQw",
        "colab_type": "code",
        "outputId": "33b53c49-72d2-4205-b4bf-631a5035062d",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:07 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>acc4</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.596286</th>\n",
              "    <th>3.588869</th>\n",
              "    <th>0.046645</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>3.086100</th>\n",
              "    <th>3.205763</th>\n",
              "    <th>0.274816</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>2.494411</th>\n",
              "    <th>2.749365</th>\n",
              "    <th>0.392004</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>2.144753</th>\n",
              "    <th>2.463537</th>\n",
              "    <th>0.415671</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>2.010915</th>\n",
              "    <th>2.352887</th>\n",
              "    <th>0.409237</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>1.983992</th>\n",
              "    <th>2.336967</th>\n",
              "    <th>0.408778</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHmxcbuPxtQz",
        "colab_type": "text"
      },
      "source": [
        "## Same thing with a loop = an RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD0orQQRx_MX",
        "colab_type": "text"
      },
      "source": [
        "Instead of repeated code as seen in previous Model0 class, we will use a loop to make our code cleaner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IqZLOBoxtQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)  # green arrow\n",
        "        self.h_h = nn.Linear(nh,nh)     # brown arrow\n",
        "        self.h_o = nn.Linear(nh,nv)     # blue arrow\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = self.bn(F.relu(self.h_h(h)))\n",
        "        return self.h_o(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZn8EmYdxtQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model1(), loss_func=loss4, metrics=acc4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTGHHeIVxtQ7",
        "colab_type": "code",
        "outputId": "b92e9286-fa77-44f3-d45c-6b0efbbf1223",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(6, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:07 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>acc4</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.493525</th>\n",
              "    <th>3.420231</th>\n",
              "    <th>0.156250</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>2.987600</th>\n",
              "    <th>2.937893</th>\n",
              "    <th>0.376149</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>2.440199</th>\n",
              "    <th>2.477995</th>\n",
              "    <th>0.388787</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>2.132837</th>\n",
              "    <th>2.256569</th>\n",
              "    <th>0.391774</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>2.011305</th>\n",
              "    <th>2.181337</th>\n",
              "    <th>0.392923</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>1.985913</th>\n",
              "    <th>2.170874</th>\n",
              "    <th>0.393153</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZMH_vHCxtQ-",
        "colab_type": "text"
      },
      "source": [
        "## Multi fully connected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8rgSFwcxtQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change bptt\n",
        "data = src.databunch(bs=bs, bptt=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDosUxu8xtRC",
        "colab_type": "code",
        "outputId": "588da17c-c62a-4390-ee94-32948d0824a2",
        "colab": {}
      },
      "source": [
        "x,y = data.one_batch()\n",
        "x.shape,y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 20]), torch.Size([64, 20]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Z3Yja9xtRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "        #create array to predict a word after every word\n",
        "        res = []\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            #append the prediction after every word\n",
        "            res.append(self.h_o(self.bn(h)))\n",
        "        return torch.stack(res, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byjWAA2zxtRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model2(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRJ-5lI-xtRK",
        "colab_type": "code",
        "outputId": "21b0b166-f154-4497-99eb-ae998d228e8c",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(10, 1e-4, pct_start=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:06 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.639285</th>\n",
              "    <th>3.709278</th>\n",
              "    <th>0.058949</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>3.551151</th>\n",
              "    <th>3.565677</th>\n",
              "    <th>0.151776</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>3.439908</th>\n",
              "    <th>3.431850</th>\n",
              "    <th>0.207741</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>3.323083</th>\n",
              "    <th>3.314237</th>\n",
              "    <th>0.283949</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>3.213422</th>\n",
              "    <th>3.219906</th>\n",
              "    <th>0.321662</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>3.119673</th>\n",
              "    <th>3.151162</th>\n",
              "    <th>0.336790</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>3.046645</th>\n",
              "    <th>3.106630</th>\n",
              "    <th>0.341690</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>2.995379</th>\n",
              "    <th>3.082552</th>\n",
              "    <th>0.346662</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>2.963800</th>\n",
              "    <th>3.073327</th>\n",
              "    <th>0.349645</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>2.947312</th>\n",
              "    <th>3.071951</th>\n",
              "    <th>0.349787</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEFjxIL90Wzh",
        "colab_type": "text"
      },
      "source": [
        "Here we see that performance has worsened. This is because when predicting second word, we only had 1 previous word to predict with. For the third word, we only had the first two, etc. \n",
        "This is because we reset our state to 0 everytime we start a new BPTT sequence. (This happens in the line of code:\n",
        "\n",
        "\n",
        "```\n",
        "h = torch.zeros(x.shape[0], nh).to(device=x.device)\n",
        "```\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQwUWqKWxtRN",
        "colab_type": "text"
      },
      "source": [
        "## Maintain state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNr1dyZv01Bg",
        "colab_type": "text"
      },
      "source": [
        "Let's not reset the state, and keep 'h' i.e. not throw away the previous state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVB1RmLFxtRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.h_h = nn.Linear(nh,nh)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = nn.BatchNorm1d(nh)\n",
        "        self.h = torch.zeros(bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        h = self.h\n",
        "        for i in range(x.shape[1]):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "            res.append(self.bn(h))\n",
        "        self.h = h.detach()\n",
        "        res = torch.stack(res, dim=1)\n",
        "        res = self.h_o(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuIruWKYxtRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model3(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIeINu8xxtRV",
        "colab_type": "code",
        "outputId": "85b8838d-4e4a-410c-8889-385f04690102",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:11 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.598183</th>\n",
              "    <th>3.556362</th>\n",
              "    <th>0.050710</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>3.274616</th>\n",
              "    <th>2.975699</th>\n",
              "    <th>0.401634</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>2.624206</th>\n",
              "    <th>2.036894</th>\n",
              "    <th>0.467330</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>2.022702</th>\n",
              "    <th>1.956439</th>\n",
              "    <th>0.316193</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>1.681813</th>\n",
              "    <th>1.934952</th>\n",
              "    <th>0.336861</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>1.453007</th>\n",
              "    <th>1.948201</th>\n",
              "    <th>0.351349</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>1.276971</th>\n",
              "    <th>2.005776</th>\n",
              "    <th>0.368679</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>1.138499</th>\n",
              "    <th>2.081261</th>\n",
              "    <th>0.360156</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>1.029217</th>\n",
              "    <th>2.145853</th>\n",
              "    <th>0.360795</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.939949</th>\n",
              "    <th>2.215388</th>\n",
              "    <th>0.372230</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.865441</th>\n",
              "    <th>2.240438</th>\n",
              "    <th>0.401491</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.805310</th>\n",
              "    <th>2.195846</th>\n",
              "    <th>0.409375</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.755035</th>\n",
              "    <th>2.324373</th>\n",
              "    <th>0.422727</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.713073</th>\n",
              "    <th>2.305542</th>\n",
              "    <th>0.449716</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>0.677393</th>\n",
              "    <th>2.350155</th>\n",
              "    <th>0.446449</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>16</th>\n",
              "    <th>0.645841</th>\n",
              "    <th>2.418738</th>\n",
              "    <th>0.446591</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>17</th>\n",
              "    <th>0.621809</th>\n",
              "    <th>2.456903</th>\n",
              "    <th>0.446165</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>18</th>\n",
              "    <th>0.605300</th>\n",
              "    <th>2.541699</th>\n",
              "    <th>0.443040</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>19</th>\n",
              "    <th>0.594099</th>\n",
              "    <th>2.539824</th>\n",
              "    <th>0.443040</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>20</th>\n",
              "    <th>0.587563</th>\n",
              "    <th>2.551423</th>\n",
              "    <th>0.442827</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Bge70T1CiD",
        "colab_type": "text"
      },
      "source": [
        "Now our accuracy has improved more than the original one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2obr8x9XxtRX",
        "colab_type": "text"
      },
      "source": [
        "## nn.RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zzzn5s91gpZ",
        "colab_type": "text"
      },
      "source": [
        "Add another RNN at the output of previous model. More layers would mean better results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZrbleMtxtRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.RNN(nh,nh, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(1, bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1SQ5EfjxtRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model4(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdouR4_ixtRe",
        "colab_type": "code",
        "outputId": "2a9e5ac7-c0bf-4360-f9de-d7ab554a8620",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(20, 3e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:04 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>3.451432</th>\n",
              "    <th>3.268344</th>\n",
              "    <th>0.224148</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>2.974938</th>\n",
              "    <th>2.456569</th>\n",
              "    <th>0.466051</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>2.316732</th>\n",
              "    <th>1.946969</th>\n",
              "    <th>0.465625</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>1.866151</th>\n",
              "    <th>1.991952</th>\n",
              "    <th>0.314702</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>1.618516</th>\n",
              "    <th>1.802403</th>\n",
              "    <th>0.437216</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>1.411517</th>\n",
              "    <th>1.731107</th>\n",
              "    <th>0.436293</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>1.171916</th>\n",
              "    <th>1.655979</th>\n",
              "    <th>0.504048</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.965887</th>\n",
              "    <th>1.579963</th>\n",
              "    <th>0.522088</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.797046</th>\n",
              "    <th>1.479819</th>\n",
              "    <th>0.565057</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.659378</th>\n",
              "    <th>1.487831</th>\n",
              "    <th>0.579048</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>11</th>\n",
              "    <th>0.553282</th>\n",
              "    <th>1.441922</th>\n",
              "    <th>0.597798</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>12</th>\n",
              "    <th>0.475167</th>\n",
              "    <th>1.498148</th>\n",
              "    <th>0.600781</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>13</th>\n",
              "    <th>0.416131</th>\n",
              "    <th>1.546984</th>\n",
              "    <th>0.606463</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>14</th>\n",
              "    <th>0.372395</th>\n",
              "    <th>1.594261</th>\n",
              "    <th>0.607386</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>15</th>\n",
              "    <th>0.337093</th>\n",
              "    <th>1.578321</th>\n",
              "    <th>0.613352</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>16</th>\n",
              "    <th>0.311385</th>\n",
              "    <th>1.580973</th>\n",
              "    <th>0.623366</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>17</th>\n",
              "    <th>0.292869</th>\n",
              "    <th>1.625745</th>\n",
              "    <th>0.618253</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>18</th>\n",
              "    <th>0.279486</th>\n",
              "    <th>1.623960</th>\n",
              "    <th>0.626065</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>19</th>\n",
              "    <th>0.270054</th>\n",
              "    <th>1.682090</th>\n",
              "    <th>0.611719</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>20</th>\n",
              "    <th>0.263857</th>\n",
              "    <th>1.675676</th>\n",
              "    <th>0.614702</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIULoyjj19Nk",
        "colab_type": "text"
      },
      "source": [
        "We get a higher accuracy now than before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxWkdfjPxtRg",
        "colab_type": "text"
      },
      "source": [
        "## 2-layer GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJcG0PyxtRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Embedding(nv,nh)\n",
        "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
        "        self.h_o = nn.Linear(nh,nv)\n",
        "        self.bn = BatchNorm1dFlat(nh)\n",
        "        self.h = torch.zeros(2, bs, nh).cuda()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(self.bn(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m96WfIOh1sMF",
        "colab_type": "text"
      },
      "source": [
        "Here, we specified how many layers we want in the RNN. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQhLgbkKxtRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(data, Model5(), metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ4eO90oxtRn",
        "colab_type": "code",
        "outputId": "12f2a27a-f599-48a9-ede5-1cba55f5edce",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(10, 1e-2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 00:02 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>accuracy</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>2.864854</th>\n",
              "    <th>2.314943</th>\n",
              "    <th>0.454545</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>1.798988</th>\n",
              "    <th>1.357116</th>\n",
              "    <th>0.629688</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>0.932729</th>\n",
              "    <th>1.307463</th>\n",
              "    <th>0.796733</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>0.451969</th>\n",
              "    <th>1.329699</th>\n",
              "    <th>0.788636</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>5</th>\n",
              "    <th>0.225787</th>\n",
              "    <th>1.293570</th>\n",
              "    <th>0.800142</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>6</th>\n",
              "    <th>0.118085</th>\n",
              "    <th>1.265926</th>\n",
              "    <th>0.803338</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>7</th>\n",
              "    <th>0.065306</th>\n",
              "    <th>1.207096</th>\n",
              "    <th>0.806960</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>8</th>\n",
              "    <th>0.038098</th>\n",
              "    <th>1.205361</th>\n",
              "    <th>0.813920</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>9</th>\n",
              "    <th>0.024069</th>\n",
              "    <th>1.239411</th>\n",
              "    <th>0.807813</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>10</th>\n",
              "    <th>0.017078</th>\n",
              "    <th>1.253409</th>\n",
              "    <th>0.807102</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hnh6Ojl2CEi",
        "colab_type": "text"
      },
      "source": [
        "Hurray, now our accuracy is up, to 80%. "
      ]
    }
  ]
}